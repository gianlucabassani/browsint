# Contiene funzioni per formattare i dati per la presentazione (es. report HTML)

try:
    from reportlab.lib.pagesizes import letter, A4
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch
    from reportlab.lib.colors import HexColor, black, white
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
    from reportlab.platypus.frames import Frame
    from reportlab.platypus.doctemplate import BaseDocTemplate, PageTemplate
    from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_JUSTIFY
    from io import BytesIO
    import html
    REPORTLAB_AVAILABLE = True
except ImportError:
    REPORTLAB_AVAILABLE = False
    print("Warning: ReportLab not available. PDF generation will be disabled.")
    print("Install it with: pip install reportlab")

try:
    import pdfkit
    PDFKIT_AVAILABLE = True
except ImportError:
    PDFKIT_AVAILABLE = False
    print("Warning: pdfkit not available. HTML-to-PDF conversion will be disabled.")
    print("Install it with: pip install pdfkit && sudo apt install wkhtmltopdf")

from datetime import datetime, timezone
from typing import Any, Dict, List, Optional
from colorama import Fore, Style
from urllib.parse import urlparse
from pathlib import Path
import re
#from fpdf import FPDF

# Palette di colori blu professionale
HEADER_BLUE = Fore.BLUE + Style.BRIGHT
SECTION_BLUE = Fore.CYAN + Style.BRIGHT
ACCENT_BLUE = Fore.LIGHTBLUE_EX
DATA_BLUE = Fore.BLUE
WARNING_BLUE = Fore.LIGHTCYAN_EX
TEXT_WHITE = Fore.WHITE + Style.BRIGHT
SEPARATOR_BLUE = Fore.CYAN + Style.DIM

def generate_html_report(profile: dict) -> str:
    """
    Genera un report HTML da un profilo OSINT.

    Args:
        profile (dict): Dizionario contenente i dati del profilo OSINT.

    Returns:
        str: Una stringa contenente il codice HTML del report.
    """
    domain = profile.get("entity", {}).get("name", "N/A")

    html = f"""<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OSINT Report: {domain}</title>
    <style>
        body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 0; padding: 20px; background-color: #f4f7f6; color: #333; }}
        .container {{ max-width: 960px; margin: 20px auto; background-color: #fff; padding: 25px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        .header {{ background-color: #005f73; color: white; padding: 20px; margin-bottom: 25px; border-radius: 5px; text-align: center; }}
        .section {{ background-color: #e9ecef; padding: 20px; margin-bottom: 20px; border-radius: 5px; border-left: 5px solid #0077b6; }}
        .section h2 {{ color: #005f73; margin-top: 0; border-bottom: 2px solid #ade8f4; padding-bottom: 10px; }}
        .label {{ font-weight: bold; color: #0077b6; min-width: 180px; display: inline-block; }}
        p {{ line-height: 1.6; }}
        ul {{ list-style-type: none; padding-left: 0; }}
        li {{ background-color: #fff; margin-bottom: 8px; padding: 10px; border-radius: 4px; border: 1px solid #dee2e6; }}
        .footer {{ margin-top: 30px; text-align: center; font-size: 0.9em; color: #6c757d; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>OSINT Profile Report</h1>
            <p>Target: {domain}</p>
            <p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
"""

    html += """
        <div class="footer">
            <p>Generated by OSINT Extractor Tool</p>
        </div>
    </div>
</body>
</html>
"""
    return html

def text_report_to_html(text: str) -> str:
    """
    Converte un report testuale (con eventuali codici colore ANSI) in HTML semplice, preservando sezioni e a capo.

    Args:
        text (str): Testo del report da convertire.

    Returns:
        str: HTML risultante.
    """
    # Improved regex to remove all ANSI escape codes
    ansi_escape = re.compile(r'(\x1B\[[0-9;]*[A-Za-z])|([\u001b\u009b][[\]()#;?]*(?:[0-9]{1,4}(?:;[0-9]{0,4})*)?[0-9A-ORZcf-nqry=><~])')
    lines = text.splitlines()
    html_lines = []
    for line in lines:
        clean = ansi_escape.sub('', line)
        html_lines.append(html.escape(clean))
    html_content = "<pre style='font-family:monospace; background:#f4f7f6; color:#222; padding:1em;'>\n" + "\n".join(html_lines) + "\n</pre>"
    return f"""<!DOCTYPE html><html><head><meta charset='utf-8'><title>OSINT Report</title></head><body>{html_content}</body></html>"""


def create_pdf_from_html(html_content: str, output_path: str, fallback_text: str = None) -> None:
    """
    Crea un PDF a partire da HTML usando pdfkit se disponibile, altrimenti usa ReportLab per un PDF testuale.

    Args:
        html_content (str): HTML da convertire in PDF.
        output_path (str): Percorso di output del PDF.
        fallback_text (str, opzionale): Testo da usare se la conversione HTML fallisce.

    Returns:
        None
    """
    if not PDFKIT_AVAILABLE:
        if fallback_text:
            print("[WARN] pdfkit not available, falling back to text-based PDF.")
            _create_pdf_from_text(fallback_text, output_path)
            return
        raise ImportError("pdfkit is required for HTML-to-PDF conversion. Install it with: pip install pdfkit && sudo apt install wkhtmltopdf")
    try:
        pdfkit.from_string(html_content, output_path)
    except (OSError, IOError) as e:
        if fallback_text:
            print(f"[WARN] pdfkit/wkhtmltopdf error: {e}. Falling back to text-based PDF.")
            _create_pdf_from_text(fallback_text, output_path)
        else:
            raise


def create_pdf_domain_report(data: dict, target_input: str, domain_analyzed: str, shodan_skipped: bool, output_path: str, use_html: bool = True) -> None:
    """
    Crea un PDF per l'analisi di un dominio. Usa HTML-to-PDF se possibile, altrimenti fallback a ReportLab.

    Args:
        data (dict): Dati raccolti (WHOIS, DNS, Shodan, ecc.).
        target_input (str): Input originale dell'utente.
        domain_analyzed (str): Dominio effettivamente analizzato.
        shodan_skipped (bool): Se la scansione Shodan √® stata saltata.
        output_path (str): Percorso di output del PDF.
        use_html (bool): Se usare HTML-to-PDF (default True).

    Returns:
        None
    """
    try:
        html_report = formal_html_report_domain(data, target_input, domain_analyzed, shodan_skipped)
        if use_html and PDFKIT_AVAILABLE:
            create_pdf_from_html(html_report, output_path, fallback_text=None)
        else:
            raise Exception("No pdfkit, fallback to reportlab")
    except Exception:
        formal_pdf_report_domain(data, target_input, domain_analyzed, shodan_skipped, output_path)


def create_pdf_page_report(url: str, parsed_data: dict, osint_data: dict, save_paths: dict, output_path: str, use_html: bool = True) -> None:
    """
    Crea un PDF per l'analisi di una pagina web. Usa HTML-to-PDF se possibile, altrimenti fallback a ReportLab.

    Args:
        url (str): URL della pagina analizzata.
        parsed_data (dict): Dati strutturati estratti dal parser.
        osint_data (dict): Dati OSINT rilevati sulla pagina.
        save_paths (dict): Percorsi dei file salvati.
        output_path (str): Percorso di output del PDF.
        use_html (bool): Se usare HTML-to-PDF (default True).

    Returns:
        None
    """
    # Use the new formal report for both HTML and PDF
    try:
        html_report = formal_html_report_page(url, parsed_data, osint_data, save_paths)
        if use_html and PDFKIT_AVAILABLE:
            create_pdf_from_html(html_report, output_path, fallback_text=None)
        else:
            raise Exception("No pdfkit, fallback to reportlab")
    except Exception:
        # Fallback to formal PDF
        formal_pdf_report_page(url, parsed_data, osint_data, save_paths, output_path)


def create_pdf_combined_report(domain_data: dict, page_data: dict, target_input: str, domain_analyzed: str, url: str, shodan_skipped: bool, output_path: str, use_html: bool = True) -> None:
    """
    Crea un PDF combinato per analisi dominio e pagina web.

    Args:
        domain_data (dict): Dati OSINT del dominio.
        page_data (dict): Dati analisi della pagina.
        target_input (str): Input originale dell'utente.
        domain_analyzed (str): Dominio effettivamente analizzato.
        url (str): URL della pagina.
        shodan_skipped (bool): Se la scansione Shodan √® stata saltata.
        output_path (str): Percorso di output del PDF.
        use_html (bool): Se usare HTML-to-PDF (default True).

    Returns:
        None
    """
    domain_report = format_domain_osint_report(domain_data, target_input, domain_analyzed, shodan_skipped)
    page_report = format_page_analysis_report(
        url,
        page_data.get('parsed_data', {}),
        page_data.get('osint_data', {}),
        page_data.get('save_paths', {})
    )
    combined_text = domain_report + "\n\n" + page_report
    html_report = text_report_to_html(combined_text)
    if use_html and PDFKIT_AVAILABLE:
        create_pdf_from_html(html_report, output_path, fallback_text=combined_text)
    elif REPORTLAB_AVAILABLE:
        _create_pdf_from_text(combined_text, output_path, title="Complete OSINT Analysis Report")
    else:
        raise ImportError("No PDF backend available. Install pdfkit or reportlab.")


def _create_pdf_from_text(text_report: str, output_path: str, title: str = "OSINT Report") -> None:
    """
    Helper per creare un PDF semplice da testo usando ReportLab.

    Args:
        text_report (str): Testo del report.
        output_path (str): Percorso di output del PDF.
        title (str): Titolo del report (default "OSINT Report").

    Returns:
        None
    """
    if not REPORTLAB_AVAILABLE:
        raise ImportError("ReportLab is required for PDF generation. Install it with: pip install reportlab")
    from reportlab.lib.pagesizes import A4
    from reportlab.pdfgen import canvas
    from reportlab.lib.units import inch
    c = canvas.Canvas(output_path, pagesize=A4)
    width, height = A4
    c.setFont("Helvetica-Bold", 16)
    c.drawString(72, height - 72, title)
    c.setFont("Helvetica", 10)
    y = height - 100
    for line in text_report.splitlines():
        if y < 72:
            c.showPage()
            y = height - 72
            c.setFont("Helvetica", 10)
        c.drawString(72, y, line)
        y -= 14
    c.save()

def create_section_box(title: str, content_lines: list, min_width: int = 60) -> list:
    """
    Crea una sezione con box dinamico basato sul contenuto.
    Args:
        title: Titolo della sezione.
        content_lines: Lista di stringhe da includere nella sezione.
        min_width: Larghezza minima del box (default 60).
    Returns:
        list: Lista di stringhe che rappresentano la sezione formattata.
    """
    
    def strip_ansi_codes(text):
        ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
        return ansi_escape.sub('', text)
    
    # Larghezze standard per diversi tipi di sezioni
    STANDARD_WIDTH = 70  # Larghezza standard per la maggior parte delle sezioni
    WIDE_WIDTH = 140     # Larghezza per sezioni con contenuto lungo (es. DNS records)
    HEADER_WIDTH = 70    # Larghezza fissa per l'header principale
    
    # Calcola la larghezza massima necessaria del contenuto
    content_width = max([len(strip_ansi_codes(line)) for line in content_lines] + [0])
    
    # Determina la larghezza appropriata basata sul contenuto e il titolo
    if "RECORD DNS" in title or "PUNTI DI INTERESSE" in title:
        box_width = WIDE_WIDTH
    else:
        box_width = min(max(STANDARD_WIDTH, content_width + 4), WIDE_WIDTH)
    
    # Calcola padding per centrare il titolo
    title_padding = (box_width - len(title) - 2) // 2
    remaining_padding = box_width - title_padding - len(title) - 2
    title_line = f"{'‚îÅ' * title_padding} {title} {'‚îÅ' * remaining_padding}"
    
    result = []
    result.append(f"{SECTION_BLUE}‚îè{title_line}‚îì{Style.RESET_ALL}")
    
    for line in content_lines:
        # Calcola il padding necessario per allineare il contenuto
        content_length = len(strip_ansi_codes(line))
        padding = " " * (box_width - content_length)
        result.append(f"{line}{padding}")
    
    result.append(f"{SECTION_BLUE}‚îó{'‚îÅ' * box_width}‚îõ{Style.RESET_ALL}")
    return result


def format_domain_osint_report(data: Dict[str, Any], target_input: str, domain_analyzed: str, shodan_skipped: bool) -> str:
    """
    Formatta i dati OSINT di un dominio per un report testuale migliorato.

    Args:
        data: Dizionario contenente i dati grezzi raccolti (WHOIS, DNS, Shodan, etc.).
        target_input: L'input originale dell'utente (es. URL completo).
        domain_analyzed: Il dominio effettivo che √® stato analizzato dopo la pulizia.
        shodan_skipped: Booleano che indica se la scansione Shodan √® stata saltata.

    Returns:
        str: Il report testuale formattato.
    """
    report_parts = []
    HEADER_WIDTH = 70  # Larghezza fissa per l'header

    # Header principale con design migliorato
    report_parts.append(f"\n{HEADER_BLUE}{'‚ïî' + '‚ïê' * (HEADER_WIDTH-2) + '‚ïó'}{Style.RESET_ALL}")
    report_parts.append(f"{HEADER_BLUE}‚ïë {TEXT_WHITE}{'üîç ANALISI DOMINIO (OSINT ESTERNO)':^{HEADER_WIDTH-4}}{HEADER_BLUE} ‚ïë{Style.RESET_ALL}")
    report_parts.append(f"{HEADER_BLUE}{'‚ïö' + '‚ïê' * (HEADER_WIDTH-2) + '‚ïù'}{Style.RESET_ALL}\n")
    
    report_parts.append(f"{DATA_BLUE}‚îå‚îÄ Input Originale:{Style.RESET_ALL} {TEXT_WHITE}{target_input}{Style.RESET_ALL}")
    report_parts.append(f"{DATA_BLUE}‚îî‚îÄ Dominio Analizzato:{Style.RESET_ALL} {TEXT_WHITE}{domain_analyzed.upper()}{Style.RESET_ALL}\n")

    # Riepilogo Rapido
    summary_content = []
    whois_data = data.get("whois", {})
    dns_data = data.get("dns", {})

    registrar = whois_data.get("registrar", "N/A")
    summary_content.append(f"{DATA_BLUE}  ‚ñ∂ Registrar:{Style.RESET_ALL} {TEXT_WHITE}{registrar}{Style.RESET_ALL}")

    privacy_shield = "No"
    organization = whois_data.get("organization", "")
    if "contact privacy" in organization.lower() or "proxy" in organization.lower():
        privacy_shield = f"{TEXT_WHITE}S√¨{Style.RESET_ALL} {Fore.CYAN}(Dettagli nascosti){Style.RESET_ALL}"
    else:
        privacy_shield = f"{TEXT_WHITE}No{Style.RESET_ALL}"
    summary_content.append(f"{DATA_BLUE}  ‚ñ∂ Servizio di Privacy WHOIS:{Style.RESET_ALL} {privacy_shield}")

    creation_date_str = whois_data.get("creation_date")
    domain_age = "N/A"
    if creation_date_str:
        try:
            # Parse ISO-like strings or accept a datetime object
            if isinstance(creation_date_str, str):
                parsed = datetime.fromisoformat(creation_date_str.replace('Z', '+00:00') if 'Z' in creation_date_str else creation_date_str)
            elif isinstance(creation_date_str, datetime):
                parsed = creation_date_str
            else:
                parsed = datetime.fromisoformat(str(creation_date_str))

            # Normalize to timezone-aware UTC for safe arithmetic
            if parsed.tzinfo is None:
                creation_date = parsed.replace(tzinfo=timezone.utc)
            else:
                creation_date = parsed.astimezone(timezone.utc)

            now_utc = datetime.now(timezone.utc)
            age_delta = now_utc - creation_date
            years = age_delta.days // 365
            months = (age_delta.days % 365) // 30
            domain_age = f"{TEXT_WHITE}{years} anni, {months} mesi{Style.RESET_ALL} {TEXT_WHITE}(Registrato il {creation_date.strftime('%d %b %Y')}{Style.RESET_ALL}){Style.RESET_ALL}"
        except Exception:
            domain_age = f"{TEXT_WHITE}Errore parsing data: {creation_date_str}{Style.RESET_ALL}"
    summary_content.append(f"{DATA_BLUE}  ‚ñ∂ Et√† Dominio:{Style.RESET_ALL} {domain_age}")

    name_servers = dns_data.get("NS", ["N/A"])
    summary_content.append(f"{DATA_BLUE}  ‚ñ∂ Name Servers:{Style.RESET_ALL} {TEXT_WHITE}{', '.join(name_servers)}{Style.RESET_ALL}")

    a_records = dns_data.get("A", [])
    if a_records:
        summary_content.append(f"{DATA_BLUE}  ‚ñ∂ IP Principali (A Records):{Style.RESET_ALL} {TEXT_WHITE}{', '.join(a_records)}{Style.RESET_ALL}")
    else:
        summary_content.append(f"{DATA_BLUE}  ‚ñ∂ IP Principali (A Records):{Style.RESET_ALL} {Fore.RED}Nessuno trovato{Style.RESET_ALL}")

    mx_records = dns_data.get("MX", [])
    if mx_records:
        mx_display = mx_records[0].split(' ')[1] if mx_records[0] else 'N/A'
        extra_count = len(mx_records) - 1
        if extra_count > 0:
            mx_display += f" {Fore.CYAN}(+{extra_count} altri){Style.RESET_ALL}"
        summary_content.append(f"{DATA_BLUE}  ‚ñ∂ Servizio Email (MX):{Style.RESET_ALL} {TEXT_WHITE}{mx_display}{Style.RESET_ALL}")
    else:
        summary_content.append(f"{DATA_BLUE}  ‚ñ∂ Servizio Email (MX):{Style.RESET_ALL} {Fore.RED}Nessuno trovato{Style.RESET_ALL}")
    
    # Esempio di come usare create_section_box:
    report_parts.extend(create_section_box("RIEPILOGO RAPIDO", summary_content))
    report_parts.append("")

    # Informazioni WHOIS
    whois_content = []
    whois_content.append(f"{DATA_BLUE}  ‚îå‚îÄ Nome Dominio:{Style.RESET_ALL}      {TEXT_WHITE}{whois_data.get('domain_name', 'N/A')}{Style.RESET_ALL}")
    whois_content.append(f"{DATA_BLUE}  ‚îú‚îÄ Registrar:{Style.RESET_ALL}         {TEXT_WHITE}{whois_data.get('registrar', 'N/A')}{Style.RESET_ALL}")
    whois_content.append(f"{DATA_BLUE}  ‚îú‚îÄ Data Creazione:{Style.RESET_ALL}    {TEXT_WHITE}{whois_data.get('creation_date', 'N/A')}{Style.RESET_ALL}")
    whois_content.append(f"{DATA_BLUE}  ‚îú‚îÄ Data Scadenza:{Style.RESET_ALL}     {TEXT_WHITE}{whois_data.get('expiration_date', 'N/A')}{Style.RESET_ALL}")
    whois_content.append(f"{DATA_BLUE}  ‚îî‚îÄ Ultimo Aggiorn.:{Style.RESET_ALL}   {TEXT_WHITE}{whois_data.get('last_updated', 'N/A')}{Style.RESET_ALL}")
    
    status = whois_data.get("status", [])
    if status:
        whois_content.append(f"{DATA_BLUE}  ‚îå‚îÄ Stato Dominio:{Style.RESET_ALL}     {TEXT_WHITE}{', '.join(status)}{Style.RESET_ALL}")
        whois_content.append(f"{DATA_BLUE}  ‚îî‚îÄ{Style.RESET_ALL} {Fore.CYAN}(Tipico per protezione da trasferimenti indesiderati){Style.RESET_ALL}")
    else:
        whois_content.append(f"{DATA_BLUE}  ‚îî‚îÄ Stato Dominio:{Style.RESET_ALL}     {Fore.RED}N/A{Style.RESET_ALL}")

    organization_display = whois_data.get('organization', 'N/A')
    if "contact privacy" in organization_display.lower() or "proxy" in organization_display.lower():
        organization_display = f"{organization_display} {Fore.CYAN}‚ö†Ô∏è (PRIVACY ATTIVA: Dettagli proprietario nascosti){Style.RESET_ALL}"
    whois_content.append(f"{DATA_BLUE}  ‚îî‚îÄ Organization:{Style.RESET_ALL}      {TEXT_WHITE}{organization_display}{Style.RESET_ALL}")

    emails = whois_data.get("emails", [])
    if emails:
        whois_content.append(f"{DATA_BLUE}  ‚îî‚îÄ Emails di Contatto WHOIS:{Style.RESET_ALL}")
        for i, email in enumerate(emails):
            prefix = "‚îú‚îÄ" if i < len(emails) - 1 else "‚îî‚îÄ"
            whois_content.append(f"{DATA_BLUE}     {prefix} {TEXT_WHITE}{email}{Style.RESET_ALL}")
    else:
        whois_content.append(f"{DATA_BLUE}  ‚îî‚îÄ Emails di Contatto WHOIS:{Style.RESET_ALL} {Fore.RED}Nessuna trovata{Style.RESET_ALL}")
    
    report_parts.extend(create_section_box("INFORMAZIONI WHOIS", whois_content))
    report_parts.append("")

    # Record DNS
    dns_content = []
    for record_type in ["A", "AAAA", "MX", "NS", "SOA", "TXT"]:
        records = dns_data.get(record_type, [])
        if records:
            dns_content.append(f"{DATA_BLUE}  ‚îå‚îÄ Record {record_type}:{Style.RESET_ALL}")
            for i, record in enumerate(records):
                prefix = "‚îú‚îÄ" if i < len(records) - 1 else "‚îî‚îÄ"
                dns_content.append(f"{DATA_BLUE}  ‚îÇ  {prefix} {TEXT_WHITE}{record}{Style.RESET_ALL}")
        else:
            dns_content.append(f"{DATA_BLUE}  ‚îî‚îÄ Record {record_type}:{Style.RESET_ALL} {Fore.RED}Nessuno trovato{Style.RESET_ALL}")
    
    report_parts.extend(create_section_box("RECORD DNS", dns_content))
    report_parts.append("")

    # Scansione Shodan
    shodan_content = []
    if shodan_skipped:
        shodan_content.append(f"{Fore.RED}  ‚ö†Ô∏è  Scansione Shodan saltata dall'utente.{Style.RESET_ALL}")
        shodan_content.append(f"{Fore.RED}      Riprova e abilitala per dettagli su porte/servizi.{Style.RESET_ALL}")
    else:
        shodan_data = data.get("shodan", {})
        if shodan_data and shodan_data.get("hostnames"):
            shodan_content.append(f"{DATA_BLUE}  ‚îå‚îÄ IP:{Style.RESET_ALL} {TEXT_WHITE}{shodan_data.get('ip_str', 'N/A')}{Style.RESET_ALL}")
            shodan_content.append(f"{DATA_BLUE}  ‚îú‚îÄ Organizzazione:{Style.RESET_ALL} {TEXT_WHITE}{shodan_data.get('org', 'N/A')}{Style.RESET_ALL}")
            shodan_content.append(f"{DATA_BLUE}  ‚îú‚îÄ ISP:{Style.RESET_ALL} {TEXT_WHITE}{shodan_data.get('isp', 'N/A')}{Style.RESET_ALL}")
            shodan_content.append(f"{DATA_BLUE}  ‚îú‚îÄ Paese:{Style.RESET_ALL} {TEXT_WHITE}{shodan_data.get('country_name', 'N/A')}{Style.RESET_ALL}")
            shodan_content.append(f"{DATA_BLUE}  ‚îî‚îÄ Porte Aperte e Servizi:{Style.RESET_ALL}")
            for i, port_info in enumerate(shodan_data.get('ports_info', [])):
                prefix = "‚îú‚îÄ" if i < len(shodan_data.get('ports_info', [])) - 1 else "‚îî‚îÄ"
                port = port_info.get('port', 'N/A')
                service = port_info.get('product', 'N/A')
                shodan_content.append(f"{DATA_BLUE}     {prefix} Porta: {TEXT_WHITE}{port}{Style.RESET_ALL}, Servizio: {TEXT_WHITE}{service}{Style.RESET_ALL}")
        else:
            shodan_content.append(f"{Fore.RED}  ‚ùå Nessun dato Shodan disponibile o host non trovato.{Style.RESET_ALL}")
    
    report_parts.extend(create_section_box("SCANSIONE SHODAN", shodan_content))
    report_parts.append("")

    # Wayback Machine
    wayback_content = []
    wayback_info = data.get("wayback_machine", {})

    if wayback_info.get("error"):
        wayback_content.append(f"{WARNING_BLUE} ¬†Status: {wayback_info['error']}{Style.RESET_ALL}")
    elif wayback_info.get("info"):
        wayback_content.append(f" ¬†{Fore.CYAN}{wayback_info['info']}{Style.RESET_ALL}")
    elif snapshots := wayback_info.get("snapshots"):
        wayback_content.append(f"{DATA_BLUE} ¬†‚ñ∂ Ultimi {min(len(snapshots), 5)} Snapshot:{Style.RESET_ALL}")
        for i, s in enumerate(snapshots[:5]): # Mostra solo i primi 5 per concisione
            prefix = "‚îú‚îÄ" if i < min(len(snapshots), 5) - 1 else "‚îî‚îÄ"
            timestamp = s.get('timestamp', 'N/A')
            url = s.get('url', 'N/A')
            wayback_content.append(f" ¬† ¬†{prefix} {TEXT_WHITE}{timestamp}: {url}{Style.RESET_ALL}")
    else:
        wayback_content.append(f"{WARNING_BLUE} ¬†Nessun snapshot trovato.{Style.RESET_ALL}")

    report_parts.extend(create_section_box("WAYBACK MACHINE", wayback_content))
    report_parts.append("")
    
    # Punti di Interesse / Note
    notes_content = []
    if "contact privacy" in organization.lower() or "proxy" in organization.lower():
        notes_content.append(f"{Fore.CYAN}üîí L'identit√† del registrante del dominio √® nascosta tramite un servizio di privacy, rendendo pi√π difficile l'attribuzione diretta.{Style.RESET_ALL}")
    if "wixdns.net" in str(name_servers).lower():
        notes_content.append(f"{Fore.CYAN}üåê I Name Servers indicano che il sito √® ospitato o gestito tramite la piattaforma Wix.com.{Style.RESET_ALL}")
    if a_records:
        notes_content.append(f"{Fore.CYAN}üñ•Ô∏è Gli indirizzi IP ({TEXT_WHITE}{', '.join(a_records)} {Style.RESET_ALL} {Fore.CYAN}) sono associati a {TEXT_WHITE}Wix.com{Style.RESET_ALL}{Fore.CYAN}, confermando l'hosting.{Style.RESET_ALL}")
    if creation_date_str:
         notes_content.append(f"{Fore.CYAN}üìÖ Il dominio √® attivo da {TEXT_WHITE}{domain_age.split('(')[0].strip()}{Fore.CYAN}, indicando una presenza consolidata.{Style.RESET_ALL}")
    if "TXT" in dns_data:
        for txt_rec in dns_data["TXT"]:
            if "spf" in txt_rec.lower():
                notes_content.append(f"{Fore.CYAN}üìß Il record SPF ({TEXT_WHITE}`{txt_rec}`{Fore.CYAN}) specifica i server autorizzati per l'invio di email, inclusi Wix e/o Aruba.{Style.RESET_ALL}")

    report_parts.extend(create_section_box("PUNTI DI INTERESSE / NOTE", notes_content))
    report_parts.append("")

    # Footer
    report_parts.append(f"{HEADER_BLUE}{'‚ïö' + '‚ïê' * (HEADER_WIDTH-2) + '‚ïù'}{Style.RESET_ALL}")
    return "\n".join(report_parts)


def format_page_analysis_report(url: str, parsed_data: Dict[str, Any], osint_data: Dict[str, Any], save_paths: Dict[str, Path]) -> str:
    """
    Formatta i risultati dell'analisi di una singola pagina web per un report testuale migliorato.

    Args:
        url: L'URL della pagina analizzata.
        parsed_data: I dati strutturati estratti dal parser (titolo, links, meta, ecc.).
        osint_data: I dati OSINT rilevati sulla pagina (email, telefoni, tecnologie).
        save_paths: Dizionario con i percorsi dove sono stati salvati i file (HTML, JSON).

    Returns:
        str: Il report testuale formattato.
    """
    report_parts = []
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    HEADER_WIDTH = 70  # Larghezza fissa per l'header

    # Header principale con design migliorato
    report_parts.append(f"\n{HEADER_BLUE}{'‚ïî' + '‚ïê' * (HEADER_WIDTH-2) + '‚ïó'}{Style.RESET_ALL}")
    report_parts.append(f"{HEADER_BLUE}‚ïë {TEXT_WHITE}{'üåê ANALISI LOCALE PAGINA WEB':^{HEADER_WIDTH-4}}{HEADER_BLUE} ‚ïë{Style.RESET_ALL}")
    report_parts.append(f"{HEADER_BLUE}{'‚ïö' + '‚ïê' * (HEADER_WIDTH-2) + '‚ïù'}{Style.RESET_ALL}\n")
    
    report_parts.append(f"{DATA_BLUE}‚îå‚îÄ URL Analizzato:{Style.RESET_ALL} {TEXT_WHITE}{url}{Style.RESET_ALL}")
    report_parts.append(f"{DATA_BLUE}‚îî‚îÄ Data Analisi:{Style.RESET_ALL} {TEXT_WHITE}{timestamp}{Style.RESET_ALL}\n")

    # Informazioni Generali sulla Pagina
    general_content = []
    title = parsed_data.get("title", "N/A")
    description = parsed_data.get("description", "N/A")
    content_length = parsed_data.get("content_length", "N/A")
    lang_attr = parsed_data.get("lang", "N/A")
    canonical_url = parsed_data.get("canonical_url", "N/A")

    general_content.append(f"{DATA_BLUE}  ‚îå‚îÄ Titolo Pagina:{Style.RESET_ALL}     {TEXT_WHITE}{title}{Style.RESET_ALL}")
    
    desc_display = description if description and description != "N/A" else f"{TEXT_WHITE}Nessuna{Style.RESET_ALL} {Fore.CYAN}(potrebbe impattare SEO){Style.RESET_ALL}"
    general_content.append(f"{DATA_BLUE}  ‚îú‚îÄ Meta Descrizione:{Style.RESET_ALL}  {TEXT_WHITE}{desc_display}{Style.RESET_ALL}")
    
    general_content.append(f"{DATA_BLUE}  ‚îú‚îÄ URL Canonical:{Style.RESET_ALL}     {TEXT_WHITE}{canonical_url}{Style.RESET_ALL}")
    general_content.append(f"{DATA_BLUE}  ‚îú‚îÄ Lingua (HTML):{Style.RESET_ALL}     {TEXT_WHITE}{lang_attr}{Style.RESET_ALL}")
    
    size_display = f"{TEXT_WHITE}{content_length} bytes{Style.RESET_ALL} {Fore.CYAN}(circa {round(content_length/1024, 2)} KB){Style.RESET_ALL}" if isinstance(content_length, int) else f"{TEXT_WHITE}N/A{Style.RESET_ALL}"
    general_content.append(f"{DATA_BLUE}  ‚îî‚îÄ Dimensione HTML:{Style.RESET_ALL}   {TEXT_WHITE}{size_display}{Style.RESET_ALL}")
    
    report_parts.extend(create_section_box("INFORMAZIONI GENERALI SULLA PAGINA", general_content))
    report_parts.append("")

    # Statistiche Link & Media
    stats_content = []
    internal_links = parsed_data.get("internal_links_count", 0)
    external_links = parsed_data.get("external_links_count", 0)
    image_count = parsed_data.get("image_count", 0)
    css_count = parsed_data.get("css_count", 0)
    js_count = parsed_data.get("js_count", 0)

    stats_content.append(f"{DATA_BLUE}  ‚îå‚îÄ Link Interni Trovati:{Style.RESET_ALL}     {TEXT_WHITE}{internal_links}{Style.RESET_ALL}")
    stats_content.append(f"{DATA_BLUE}  ‚îú‚îÄ Link Esterni Trovati:{Style.RESET_ALL}     {TEXT_WHITE}{external_links}{Style.RESET_ALL}")
    stats_content.append(f"{DATA_BLUE}  ‚îú‚îÄ Immagini Rilevate:{Style.RESET_ALL}        {TEXT_WHITE}{image_count}{Style.RESET_ALL}")
    stats_content.append(f"{DATA_BLUE}  ‚îú‚îÄ Fogli di Stile (CSS):{Style.RESET_ALL}     {TEXT_WHITE}{css_count}{Style.RESET_ALL}")
    stats_content.append(f"{DATA_BLUE}  ‚îî‚îÄ Script (JS):{Style.RESET_ALL}              {TEXT_WHITE}{js_count}{Style.RESET_ALL}")
    
    report_parts.extend(create_section_box("STATISTICHE LINK & MEDIA", stats_content))
    report_parts.append("")

    # Dati di Contatto Estratti
    contacts_content = []
    emails = osint_data.get("emails", [])
    phones = osint_data.get("phone_numbers", [])
    domain = urlparse(url).netloc

    if emails:
        contacts_content.append(f"{DATA_BLUE}  ‚îå‚îÄ Emails Trovate:{Style.RESET_ALL}")
        for i, email in enumerate(emails):
            email_domain = email.split('@')[-1]
            status = f"{Fore.CYAN}(Interna al dominio){Style.RESET_ALL}" if email_domain == domain else f"{Fore.CYAN}(Esterna al dominio){Style.RESET_ALL}"
            prefix = "‚îú‚îÄ" if i < len(emails) - 1 else "‚îî‚îÄ"
            contacts_content.append(f"{DATA_BLUE}  ‚îÇ  {prefix} {TEXT_WHITE}{email}{Style.RESET_ALL} {status}")
    else:
        contacts_content.append(f"{DATA_BLUE}  ‚îú‚îÄ Emails Trovate:{Style.RESET_ALL} {Fore.RED}Nessuna{Style.RESET_ALL}")

    if phones:
        contacts_content.append(f"{DATA_BLUE}  ‚îî‚îÄ Numeri di Telefono Trovati:{Style.RESET_ALL}")
        for i, phone in enumerate(phones):
            prefix = "‚îú‚îÄ" if i < len(phones) - 1 else "‚îî‚îÄ"
            contacts_content.append(f"{DATA_BLUE}     {prefix} {TEXT_WHITE}{phone}{Style.RESET_ALL}")
    else:
        contacts_content.append(f"{DATA_BLUE}  ‚îî‚îÄ Numeri di Telefono Trovati:{Style.RESET_ALL} {Fore.RED}Nessuno{Style.RESET_ALL}")

    report_parts.extend(create_section_box("DATI DI CONTATTO ESTRATTI", contacts_content))
    report_parts.append("")

    # Tecnologie & Configurazione Web
    tech_content = []
    technologies = osint_data.get("page_technologies", {})

    cms_framework = technologies.get("framework_cms", "Sconosciuto")
    tech_content.append(f"{WARNING_BLUE}  ‚îå‚îÄ CMS / Framework:{Style.RESET_ALL} {TEXT_WHITE}{cms_framework}{Style.RESET_ALL}")

    web_server = technologies.get("web_server", "Sconosciuto")
    tech_content.append(f"{WARNING_BLUE}  ‚îú‚îÄ Web Server:{Style.RESET_ALL} {TEXT_WHITE}{web_server}{Style.RESET_ALL}")

    js_libraries = technologies.get("js_libraries", [])
    if js_libraries:
        tech_content.append(f"{WARNING_BLUE}  ‚îú‚îÄ Librerie JavaScript:{Style.RESET_ALL} {TEXT_WHITE}{', '.join(js_libraries)}{Style.RESET_ALL}")
    else:
        tech_content.append(f"{WARNING_BLUE}  ‚îú‚îÄ Librerie JavaScript:{Style.RESET_ALL} {Fore.RED}Nessuna rilevata{Style.RESET_ALL}")

    # Header di Sicurezza
    security_headers = technologies.get("security_headers", {})
    if security_headers:
        tech_content.append(f"{DATA_BLUE}  ‚îú‚îÄ {Fore.CYAN}Header di Sicurezza HTTP:{Style.RESET_ALL}")
        for i, (header, value) in enumerate(security_headers.items()):
            explanation = ""
            if header.lower() == "strict-transport-security":
                explanation = f"{Fore.CYAN}(HSTS: Forza l'uso di HTTPS){Style.RESET_ALL}"
            elif header.lower() == "x-content-type-options":
                explanation = f"{Fore.CYAN}(Impedisce al browser di 'indovinare' il tipo MIME){Style.RESET_ALL}"
            
            prefix = "‚îú‚îÄ" if i < len(security_headers) - 1 else "‚îî‚îÄ"
            tech_content.append(f"{DATA_BLUE}  ‚îÇ  {prefix} {header}:{Style.RESET_ALL} {TEXT_WHITE}{value}{Style.RESET_ALL} {explanation}")
    else:
        tech_content.append(f"{DATA_BLUE}  ‚îú‚îÄ Header di Sicurezza HTTP:{Style.RESET_ALL} {Fore.RED}Nessuno rilevato o significativo{Style.RESET_ALL}")

    # Meta Tags
    meta_tags = technologies.get("meta_tags", {})
    if meta_tags:
        tech_content.append(f"{DATA_BLUE}  ‚îú‚îÄ {WARNING_BLUE}Meta Tags Rilevati:{Style.RESET_ALL}")
        
        standard_meta = {k: v for k, v in meta_tags.items() if not k.startswith(('og:', 'twitter:'))}
        if standard_meta:
            tech_content.append(f"{DATA_BLUE}  ‚îÇ  ‚îå‚îÄ {Fore.CYAN}Standard:{Style.RESET_ALL}")
            for i, (name, content) in enumerate(standard_meta.items()):
                prefix = "‚îú‚îÄ" if i < len(standard_meta) - 1 else "‚îî‚îÄ"
                tech_content.append(f"{DATA_BLUE}  ‚îÇ  ‚îÇ  {prefix} {name}:{Style.RESET_ALL} {TEXT_WHITE}{content}{Style.RESET_ALL}")

        og_meta = {k: v for k, v in meta_tags.items() if k.startswith('og:')}
        if og_meta:
            tech_content.append(f"{DATA_BLUE}  ‚îÇ  ‚îú‚îÄ {Fore.CYAN}Open Graph (OGP):{Style.RESET_ALL}")
            for i, (name, content) in enumerate(og_meta.items()):
                prefix = "‚îú‚îÄ" if i < len(og_meta) - 1 else "‚îî‚îÄ"
                tech_content.append(f"{DATA_BLUE}  ‚îÇ  ‚îÇ  {prefix} {name}:{Style.RESET_ALL} {TEXT_WHITE}{content}{Style.RESET_ALL}")
        
        twitter_meta = {k: v for k, v in meta_tags.items() if k.startswith('twitter:')}
        if twitter_meta:
            tech_content.append(f"{DATA_BLUE}  ‚îÇ  ‚îî‚îÄ {Fore.CYAN}Twitter Card:{Style.RESET_ALL}")
            for i, (name, content) in enumerate(twitter_meta.items()):
                prefix = "‚îú‚îÄ" if i < len(twitter_meta) - 1 else "‚îî‚îÄ"
                tech_content.append(f"{DATA_BLUE}  ‚îÇ     {prefix} {name}:{Style.RESET_ALL} {TEXT_WHITE}{content}{Style.RESET_ALL}")
    else:
        tech_content.append(f"{DATA_BLUE}  ‚îú‚îÄ Meta Tags Rilevati:{Style.RESET_ALL} {Fore.RED}Nessuno{Style.RESET_ALL}")

    analytics = technologies.get("analytics", "Nessuno")
    tech_content.append(f"{DATA_BLUE}  ‚îî‚îÄ Servizi di Analytics:{Style.RESET_ALL}  {TEXT_WHITE}{analytics}{Style.RESET_ALL}")

    report_parts.extend(create_section_box("TECNOLOGIE & CONFIGURAZIONE WEB", tech_content))
    report_parts.append("")

    # Percorsi di Salvataggio
    paths_content = []
    original_html_path = save_paths.get("original_html", "N/A")
    parsed_json_path = save_paths.get("parsed_json", "N/A")
    paths_content.append(f"{DATA_BLUE}  ‚îå‚îÄ HTML Originale:{Style.RESET_ALL}   {TEXT_WHITE}{original_html_path}{Style.RESET_ALL}")
    paths_content.append(f"{DATA_BLUE}  ‚îî‚îÄ Struttura JSON:{Style.RESET_ALL}   {TEXT_WHITE}{parsed_json_path}{Style.RESET_ALL}")
    
    report_parts.extend(create_section_box("PERCORSI DI SALVATAGGIO", paths_content))
    report_parts.append("")

    # Footer
    report_parts.append(f"{HEADER_BLUE}{'‚ïö' + '‚ïê' * (HEADER_WIDTH-2) + '‚ïù'}{Style.RESET_ALL}")
    return "\n".join(report_parts)

def formal_html_report_page(url, parsed_data, osint_data, save_paths):
    """
    Genera un report HTML pulito e stilizzato per l'analisi di una pagina web.
    Args:
        url: URL della pagina analizzata.
        parsed_data: Dati strutturati estratti dal parser.
        osint_data: Dati OSINT rilevati sulla pagina.
        save_paths: Dizionario con i percorsi dei file salvati.
    Returns:
        str: HTML del report.
    """
    title = parsed_data.get("title", "N/A")
    description = parsed_data.get("description", "N/A")
    content_length = parsed_data.get("content_length", "N/A")
    lang_attr = parsed_data.get("lang", "N/A")
    canonical_url = parsed_data.get("canonical_url", "N/A")
    internal_links = parsed_data.get("internal_links_count", 0)
    external_links = parsed_data.get("external_links_count", 0)
    image_count = parsed_data.get("image_count", 0)
    css_count = parsed_data.get("css_count", 0)
    js_count = parsed_data.get("js_count", 0)
    emails = osint_data.get("emails", [])
    phones = osint_data.get("phone_numbers", [])
    domain = urlparse(url).netloc
    technologies = osint_data.get("page_technologies", {})
    # save_html = save_paths.get("original_html", "N/A")
    # save_json = save_paths.get("parsed_json", "N/A")

    html = f"""
    <!DOCTYPE html>
    <html lang='it'>
    <head>
        <meta charset='utf-8'>
        <title>OSINT Page Analysis Report</title>
        <style>
            body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: #f4f7f6; color: #222; margin: 0; }}
            .container {{ max-width: 900px; margin: 30px auto; background: #fff; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.08); padding: 32px; }}
            h1, h2 {{ color: #005f73; }}
            table {{ border-collapse: collapse; width: 100%; margin-bottom: 24px; }}
            th, td {{ border: 1px solid #dee2e6; padding: 8px 12px; text-align: left; }}
            th {{ background: #e9ecef; color: #005f73; }}
            .section {{ margin-bottom: 32px; }}
            .label {{ font-weight: bold; color: #0077b6; }}
            .footer {{ margin-top: 40px; text-align: center; color: #888; font-size: 0.95em; }}
        </style>
    </head>
    <body>
    <div class='container'>
        <h1>OSINT Page Analysis Report</h1>
        <div class='section'>
            <h2>Target</h2>
            <table>
                <tr><th>URL Analizzato</th><td>{url}</td></tr>
                <tr><th>Dominio</th><td>{domain}</td></tr>
                <tr><th>Data Analisi</th><td>{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</td></tr>
            </table>
        </div>
        <div class='section'>
            <h2>Informazioni Generali</h2>
            <table>
                <tr><th>Titolo Pagina</th><td>{title}</td></tr>
                <tr><th>Meta Descrizione</th><td>{description}</td></tr>
                <tr><th>URL Canonical</th><td>{canonical_url}</td></tr>
                <tr><th>Lingua (HTML)</th><td>{lang_attr}</td></tr>
                <tr><th>Dimensione HTML</th><td>{content_length} bytes</td></tr>
            </table>
        </div>
        <div class='section'>
            <h2>Statistiche Link & Media</h2>
            <table>
                <tr><th>Link Interni</th><td>{internal_links}</td></tr>
                <tr><th>Link Esterni</th><td>{external_links}</td></tr>
                <tr><th>Immagini</th><td>{image_count}</td></tr>
                <tr><th>CSS</th><td>{css_count}</td></tr>
                <tr><th>JS</th><td>{js_count}</td></tr>
            </table>
        </div>
        <div class='section'>
            <h2>Dati di Contatto Estratti</h2>
            <table>
                <tr><th>Emails</th><td>{', '.join(emails) if emails else 'Nessuna'}</td></tr>
                <tr><th>Numeri di Telefono</th><td>{', '.join(phones) if phones else 'Nessuno'}</td></tr>
            </table>
        </div>
        <div class='section'>
            <h2>Tecnologie & Configurazione Web</h2>
            <table>
                <tr><th>CMS / Framework</th><td>{technologies.get('framework_cms', 'Sconosciuto')}</td></tr>
                <tr><th>Web Server</th><td>{technologies.get('web_server', 'Sconosciuto')}</td></tr>
                <tr><th>Librerie JS</th><td>{', '.join(technologies.get('js_libraries', [])) if technologies.get('js_libraries') else 'Nessuna'}</td></tr>
                <tr><th>Analytics</th><td>{technologies.get('analytics', 'Nessuno')}</td></tr>
            </table>
        </div>
        <div class='footer'>
            Generato da Browsint OSINT Tool
        </div>
    </div>
    </body>
    </html>
    """
    return html

def formal_pdf_report_page(url, parsed_data, osint_data, save_paths, output_path):
    """
    Genera un report PDF pulito e stilizzato per l'analisi di una pagina web.
    Args:
        url: URL della pagina analizzata.
        parsed_data: Dati strutturati estratti dal parser.
        osint_data: Dati OSINT rilevati sulla pagina.
        save_paths: Dizionario con i percorsi dei file salvati.
        output_path: Percorso di output del PDF.
    Returns:
        None
    """
    if not REPORTLAB_AVAILABLE:
        raise ImportError("ReportLab is required for PDF generation. Install it with: pip install reportlab")
    from reportlab.lib.pagesizes import A4
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
    from reportlab.lib.styles import getSampleStyleSheet
    from reportlab.lib import colors
    doc = SimpleDocTemplate(output_path, pagesize=A4, rightMargin=40, leftMargin=40, topMargin=40, bottomMargin=40)
    styles = getSampleStyleSheet()
    styleH = styles['Heading1']
    styleH2 = styles['Heading2']
    styleN = styles['Normal']
    def para(text):
        return Paragraph(str(text), styleN)
    story = []
    story.append(Paragraph("OSINT Page Analysis Report", styleH))
    story.append(Spacer(1, 16))
    # Target
    story.append(Paragraph("Target", styleH2))
    data = [
        [para("URL Analizzato"), para(url)],
        [para("Dominio"), para(urlparse(url).netloc)],
        [para("Data Analisi"), para(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))],
    ]
    story.append(Table(data, hAlign='LEFT', style=[('BACKGROUND', (0,0), (-1,0), colors.lightgrey)]))
    story.append(Spacer(1, 12))
    # General Info
    story.append(Paragraph("Informazioni Generali", styleH2))
    data = [
        [para("Titolo Pagina"), para(parsed_data.get("title", "N/A"))],
        [para("Meta Descrizione"), para(parsed_data.get("description", "N/A"))],
        [para("URL Canonical"), para(parsed_data.get("canonical_url", "N/A"))],
        [para("Lingua (HTML)"), para(parsed_data.get("lang", "N/A"))],
        [para("Dimensione HTML"), para(f"{parsed_data.get('content_length', 'N/A')} bytes")],
    ]
    story.append(Table(data, hAlign='LEFT'))
    story.append(Spacer(1, 12))
    # Link & Media
    story.append(Paragraph("Statistiche Link & Media", styleH2))
    data = [
        [para("Link Interni"), para(parsed_data.get("internal_links_count", 0))],
        [para("Link Esterni"), para(parsed_data.get("external_links_count", 0))],
        [para("Immagini"), para(parsed_data.get("image_count", 0))],
        [para("CSS"), para(parsed_data.get("css_count", 0))],
        [para("JS"), para(parsed_data.get("js_count", 0))],
    ]
    story.append(Table(data, hAlign='LEFT'))
    story.append(Spacer(1, 12))
    # Contacts
    story.append(Paragraph("Dati di Contatto Estratti", styleH2))
    emails = osint_data.get("emails", [])
    phones = osint_data.get("phone_numbers", [])
    data = [
        [para("Emails"), para(", ".join(emails) if emails else "Nessuna")],
        [para("Numeri di Telefono"), para(", ".join(phones) if phones else "Nessuno")],
    ]
    story.append(Table(data, hAlign='LEFT'))
    story.append(Spacer(1, 12))
    # Technologies
    story.append(Paragraph("Tecnologie & Configurazione Web", styleH2))
    technologies = osint_data.get("page_technologies", {})
    data = [
        [para("CMS / Framework"), para(technologies.get("framework_cms", "Sconosciuto"))],
        [para("Web Server"), para(technologies.get("web_server", "Sconosciuto"))],
        [para("Librerie JS"), para(", ".join(technologies.get("js_libraries", [])) if technologies.get("js_libraries") else "Nessuna")],
        [para("Analytics"), para(technologies.get("analytics", "Nessuno"))],
    ]
    story.append(Table(data, hAlign='LEFT'))
    story.append(Spacer(1, 12))
    story.append(Paragraph("Generato da Browsint OSINT Tool", styleN))
    doc.build(story)

def formal_html_report_domain(data, target_input, domain_analyzed, shodan_skipped):
    """
    Genera un report HTML pulito e stilizzato per il profilo dominio OSINT.
    Args:
        data: Dati raccolti (WHOIS, DNS, Shodan, ecc.).
        target_input: Input originale dell'utente.
        domain_analyzed: Dominio effettivamente analizzato.
        shodan_skipped: Booleano, se la scansione Shodan √® stata saltata.
    Returns:
        str: HTML del report.
    """
    whois = data.get("whois", {})
    dns = data.get("dns", {})
    shodan = data.get("shodan", {})
    emails = whois.get("emails", [])
    name_servers = dns.get("NS", [])
    a_records = dns.get("A", [])
    mx_records = dns.get("MX", [])
    domain = domain_analyzed
    wayback_info = data.get("wayback_machine", {})

    html = f"""
    <!DOCTYPE html>
    <html lang='it'>
    <head>
        <meta charset='utf-8'>
        <title>OSINT Domain Profile Report</title>
        <style>
            body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: #f4f7f6; color: #222; margin: 0; }}
            .container {{ max-width: 900px; margin: 30px auto; background: #fff; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.08); padding: 32px; }}
            h1, h2 {{ color: #005f73; }}
            table {{ border-collapse: collapse; width: 100%; margin-bottom: 24px; }}
            th, td {{ border: 1px solid #dee2e6; padding: 8px 12px; text-align: left; }}
            th {{ background: #e9ecef; color: #005f73; }}
            .section {{ margin-bottom: 32px; }}
            .label {{ font-weight: bold; color: #0077b6; }}
            .footer {{ margin-top: 40px; text-align: center; color: #888; font-size: 0.95em; }}
        </style>
    </head>
    <body>
    <div class='container'>
        <h1>OSINT Domain Profile Report</h1>
        <div class='section'>
            <h2>Target</h2>
            <table>
                <tr><th>Input Originale</th><td>{target_input}</td></tr>
                <tr><th>Dominio Analizzato</th><td>{domain}</td></tr>
                <tr><th>Data Analisi</th><td>{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</td></tr>
            </table>
        </div>
        <div class='section'>
            <h2>WHOIS</h2>
            <table>
                <tr><th>Nome Dominio</th><td>{whois.get('domain_name', 'N/A')}</td></tr>
                <tr><th>Registrar</th><td>{whois.get('registrar', 'N/A')}</td></tr>
                <tr><th>Data Creazione</th><td>{whois.get('creation_date', 'N/A')}</td></tr>
                <tr><th>Data Scadenza</th><td>{whois.get('expiration_date', 'N/A')}</td></tr>
                <tr><th>Ultimo Aggiornamento</th><td>{whois.get('last_updated', 'N/A')}</td></tr>
                <tr><th>Organization</th><td>{whois.get('organization', 'N/A')}</td></tr>
                <tr><th>Emails</th><td>{', '.join(emails) if emails else 'Nessuna'}</td></tr>
            </table>
        </div>
        <div class='section'>
            <h2>DNS</h2>
            <table>
                {''.join(
                    f"<tr><th>{record_type} Records</th><td>{', '.join(dns[record_type]) if dns[record_type] else 'Nessuno trovato'}</td></tr>"
                    for record_type in ["A", "AAAA", "MX", "NS", "TXT", "SOA"]
                    if record_type in dns
                )}
                {''.join(
                    f"<tr><th>{record_type} Records</th><td>{', '.join(records)}</td></tr>"
                    for record_type, records in dns.items()
                    if record_type not in ["A", "AAAA", "MX", "NS", "TXT", "SOA"] and records and any(str(r).strip() for r in records)
                )}
            </table>
        </div>
        <div class='section'>
            <h2>Shodan</h2>
            <table>
                <tr><th>Scansione Saltata?</th><td>{'S√¨' if shodan_skipped else 'No'}</td></tr>
                <tr><th>IP</th><td>{shodan.get('ip_str', 'N/A')}</td></tr>
                <tr><th>Organizzazione</th><td>{shodan.get('org', 'N/A')}</td></tr>
                <tr><th>ISP</th><td>{shodan.get('isp', 'N/A')}</td></tr>
                <tr><th>Porte Aperte</th><td>{', '.join(str(p.get('port')) for p in shodan.get('ports_info', [])) if shodan.get('ports_info') else 'N/A'}</td></tr>
            </table>
        </div>
        <div class='section'>
            <h2>Wayback Machine</h2>
            <table>
                {''.join([
                    f"<tr><th>Status</th><td>{wayback_info['error']}</td></tr>" if wayback_info.get("error") else "",
                    f"<tr><th>Info</th><td>{wayback_info['info']}</td></tr>" if wayback_info.get("info") else "",
                    (
                        "<tr><th colspan='2'>Snapshots</th></tr>" +
                        ''.join(
                            f"<tr><td>{s.get('timestamp', 'N/A')}</td><td><a href='{s.get('url', '#')}'>{s.get('url', 'N/A')}</a></td></tr>"
                            for s in wayback_info.get("snapshots", [])[:5]
                        )
                    ) if wayback_info.get("snapshots") else "<tr><td colspan='2'>Nessun snapshot trovato.</td></tr>"
                ])}
            </table>
        </div>
        <div class='footer'>
            Generato da Browsint OSINT Tool
        </div>
    </div>
    </body>
    </html>
    """
    return html

def formal_pdf_report_domain(data, target_input, domain_analyzed, shodan_skipped, output_path):
    """
    Genera un report PDF pulito e stilizzato per il profilo dominio OSINT.
    Args:
        data: Dati raccolti (WHOIS, DNS, Shodan, ecc.).
        target_input: Input originale dell'utente.
        domain_analyzed: Dominio effettivamente analizzato.
        shodan_skipped: Booleano, se la scansione Shodan √® stata saltata.
        output_path: Percorso di output del PDF.
    Returns:
        None
    """
    if not REPORTLAB_AVAILABLE:
        raise ImportError("ReportLab is required for PDF generation. Install it with: pip install reportlab")
    from reportlab.lib.pagesizes import A4
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
    from reportlab.lib.styles import getSampleStyleSheet
    from reportlab.lib import colors

    whois = data.get("whois", {})
    dns = data.get("dns", {})
    shodan = data.get("shodan", {})
    emails = whois.get("emails", [])
    name_servers = dns.get("NS", [])
    a_records = dns.get("A", [])
    mx_records = dns.get("MX", [])
    txt_records = dns.get("TXT", [])
    soa_records = dns.get("SOA", [])
    domain = domain_analyzed

    styles = getSampleStyleSheet()
    styleH = styles['Heading1']
    styleH2 = styles['Heading2']
    styleN = styles['Normal']

    def para(text):
        return Paragraph(str(text), styleN)

    # Helper per stile tabella senza bordi e con larghezza controllata
    def clean_table(data):
        return Table(
            data,
            hAlign='LEFT',
            colWidths=[120, 350],
            style=[
                ('VALIGN', (0,0), (-1,-1), 'TOP'),
                ('LEFTPADDING', (0,0), (-1,-1), 4),
                ('RIGHTPADDING', (0,0), (-1,-1), 4),
                ('TOPPADDING', (0,0), (-1,-1), 2),
                ('BOTTOMPADDING', (0,0), (-1,-1), 2),
                ('TEXTCOLOR', (0,0), (-1,-1), colors.black),
                # No borders/separators
                ('BOX', (0,0), (-1,-1), 0, colors.white),
                ('INNERGRID', (0,0), (-1,-1), 0, colors.white),
            ]
        )

    # Inizializza la variabile story
    story = []

    # Titolo
    story.append(Paragraph("OSINT Domain Profile Report", styleH))
    story.append(Spacer(1, 16))

    # Target
    story.append(Paragraph("Target", styleH2))
    data_target = [
        ["Input Originale", target_input],
        ["Dominio Analizzato", domain],
        ["Data Analisi", datetime.now().strftime('%Y-%m-%d %H:%M:%S')],
    ]
    story.append(clean_table(data_target))
    story.append(Spacer(1, 12))

    # WHOIS
    story.append(Paragraph("WHOIS", styleH2))
    data_whois = [
        ["Nome Dominio", whois.get("domain_name", "N/A")],
        ["Registrar", whois.get("registrar", "N/A")],
        ["Data Creazione", whois.get("creation_date", "N/A")],
        ["Data Scadenza", whois.get("expiration_date", "N/A")],
        ["Ultimo Aggiornamento", whois.get("last_updated", "N/A")],
        ["Organization", whois.get("organization", "N/A")],
        ["Emails", ", ".join(emails) if emails else "Nessuna"],
    ]
    story.append(clean_table(data_whois))
    story.append(Spacer(1, 12))

    # DNS Principali
    story.append(Paragraph("DNS", styleH2))
    dns_main = [
        ["A Records", ", ".join(a_records) if a_records else "Nessuno trovato"],
        ["AAAA Records", ", ".join(dns.get("AAAA", [])) if dns.get("AAAA") else "Nessuno trovato"],
        ["MX Records", ", ".join(mx_records) if mx_records else "Nessuno trovato"],
        ["NS Records", ", ".join(name_servers) if name_servers else "Nessuno trovato"],
        ["TXT Records", ", ".join(txt_records) if txt_records else "Nessuno trovato"],
        ["SOA Records", ", ".join(soa_records) if soa_records else "Nessuno trovato"],
    ]
    story.append(clean_table(dns_main))
    story.append(Spacer(1, 8))

    # DNS Extra (solo se hanno valori)
    extra_dns = [
        [f"{record_type} Records", ", ".join(records)]
        for record_type, records in dns.items()
        if record_type not in ["A", "AAAA", "MX", "NS", "TXT", "SOA"] and records and any(str(r).strip() for r in records)
    ]
    if extra_dns:
        story.append(Paragraph("Altri Record DNS", styleH2))
        story.append(clean_table(extra_dns))
        story.append(Spacer(1, 8))

    # Wayback Machine (must be aviable in data )
    story.append(Paragraph("Wayback Machine", styleH2))
    wayback_info = data.get("wayback_machine", {}) # For domain report, data should contain wayback_machine info
    wayback_data_rows = []

    if wayback_info.get("error"):
        wayback_data_rows.append([para("Status"), para(wayback_info['error'])])
    elif wayback_info.get("info"):
        wayback_data_rows.append([para("Info"), para(wayback_info['info'])])
    elif snapshots := wayback_info.get("snapshots"):
        wayback_data_rows.append([para(f"Ultimi {min(len(snapshots), 5)} Snapshot"), para("")])
        for s in snapshots[:5]:
            timestamp_wb = s.get('timestamp', 'N/A')
            url_wb = s.get('url', 'N/A')
            wayback_data_rows.append([para(f"  {timestamp_wb}"), para(url_wb)])
    else:
        wayback_data_rows.append([para("Nessun snapshot trovato."), para("")])

    if wayback_data_rows:
        story.append(Table(wayback_data_rows, hAlign='LEFT'))
        story.append(Spacer(1, 12))

    story.append(Paragraph("Generato da Browsint OSINT Tool", styleN))
    doc = SimpleDocTemplate(output_path, pagesize=A4, rightMargin=40, leftMargin=40, topMargin=40, bottomMargin=40)
    doc.build(story)